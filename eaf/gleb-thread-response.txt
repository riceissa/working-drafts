This seems to be a pretty long thread! I haven't read all the responses in the thread, though I did skim through a lot of it and got a general sense of people's complaints. I'll post all my observations here, in no particular order.

(1) Jeff's post title (on Facebook) "Why I'm not interested in funding Intentional Insights." seems odd. The default position for any organization out there is not to fund it; it's not really saying much that you choose not to fund an organization (unless you're a really large funder with a diverse portfolio and the organization under consideration fits the criteria for that portfolio). The title could perhaps better be explained in the context of Jeff noting that he has previously funded many organizations in the same space as InIn, and therefore his non-funding of InIn is actually something noteworthy.

(2) Jeff, and some others on the thread, go beyond the claim of personally not being interested in funding InIn to claiming that it's actively harmful to the world, and that it would be better if it simply ceased to exist. Jeff's fundamental intuition for why this is the case seems to be the use of sales-y and spammy tactics. I think this complaint is mostly off, and is to some extent influenced by typical mind fallacy. The LessWrong open thread http://lesswrong.com/lw/nf7/open_thread_march_21_march_27_2016/d6y7 (that was linked earlier in the comments) provides a good discussion of this. Personally, to me, Gleb's articles are "meh". But I don't see a plausible causal chain from somebody being unimpressed with Gleb's articles to forming a negative opinion of the EA movement, or of ideas underlying effective altruism more broadly. At worst, they will just form a negative opinion of Gleb. At best, they'll get some kind of exposure to the idea, and get the sense that people at wide ranges of sophistication subscribe to these ideas.

Looking back on my personal experience, my earliest introductions to many complex ideas were based on simple, dumbed-down explanations. This is true of ideas around religion, philosophy, politics, psychology, etc. It is also true of ideas around business metrics. For instance, recently I was looking for benchmarks on email marketing, and I came across https://mailchimp.com/resources/research/email-marketing-benchmarks/ that I found quite helpful, even though people who work in email marketing would probably go "meh" for most of it. In the same way, I've found WikiHow articles that say "obvious" things quite useful, particularly for topics that are relevant to me but where I haven't had a chance to do a lot of research.

Basically, inferential distances can be huge, because of (a) differences in the amount of prior exposure and thought people have to ideas, and (b) differences in people's level of intelligence, critical thinking, etc. But even ignoring (b), (a) alone has a huge effect.

Now, I don't think Gleb actually does a good job (relative to others) in popularizing simple ideas underlying effective altruism. However, I don't think he does a terrible job, or that it's counterproductive overall. I also think people are overestimating the downsides of Gleb's articles engendering a "meh" response. I think any downsides are limited to Gleb and won't spread to the EA movement.

For instance, this post http://intentionalinsights.org/the-panama-papers-reveal-the-solution-to-global-suffering was, in my view, a fairly terrible post that I panned in feedback on a draft, but I don't see any reason to believe it could hurt the EA movement.

(3) Something more concerning is Gleb posting to fora like the EA Forum and LW with the same lax intellectual standards and sales-y approach that he takes to mass-market pieces. I think he shouldn't do that, and I think the downvotes and negative comments on the posts where he does that should serve as mechanisms to discourage him from doing that. For instance, posting a copy to LessWrong for http://lesswrong.com/lw/n94/the_valentines_day_gift_that_saves_lives/ was, I think, not appropriate to LessWrong (and he was slammed for it in the comments). And http://effective-altruism.com/ea/w1/the_science_of_effective_fundraising_four_common/ was a good idea in principle but the execution just wasn't good enough for the EA Forum (something I raised with him in comments, to which he responded graciously). In this regard, I think Claire's concern about possible vote manipulation on these fora is more concerning. There isn't a lot of transparency around votes on EAF and LessWrong, but judging from the fact that even some of Gleb's more offensive posts do get positive comments from regulars who aren't affiliated with him, I think it's likely that many of the upvotes are not by people financially connected to InIn.

(4) In general, it seems like Gleb reacts to criticism in a way that is constructive at a literal level: he often changes behavior directly in response to the criticism. At the same time, his response often doesn't get to the core of the expressed concerns, and I think this reflects a failure either on the part of those expressing concerns in communicating the underlying issues, or a failure or unwillingness on Gleb's part to incorporate that advice. My simplest explanation is that Gleb and a lot of his critics have different ways of thinking about issues, and therefore Gleb is either not understanding or understanding-but-not-agreeing-to the underlying criteria that his critics are using to generate each individual criticism.

(5) I think the paid likes controversy is a bit overblown at this point (I mostly agree with Jacy on that front). I also don't think people would even have noticed that some likes seem fake, had they actually found Gleb's posts good enough for them to think it was totally reasonable to like them. In general, given the content of his posts, I find the number of likes received by some of his more popular posts unsurprising, and I don't see the role of paid likes in the like counts of those posts to be significant.
