Holden,

I tried looking for the 25 conversations you mention (since these seem to have been among the key inputs in your evaluation process). I looked at http://www.givewell.org/conversations  but was only able to find 8 conversations under the "Artificial intelligence" heading. Are the remaining 17 conversations private? Even if the conversations are private, it would be good to have a list of whom you had the conversations with, since that better helps understand the range of perspectives that informed your thinking.

The range of participants in the conversations you have explicitly listed seems heavily biased in an "academic" direction. Of the 8 conversations, 2 are with the EFF, 2 are with grad students, 2 are with tenured or tenure-track academics, and 2 are with people who work for organizations whose goal is to raise the profile of AI risk. Notably missing from this list are people who have deployed machine learning at scale in the "real world", by which I mean people who have had direct experience with and responsibility for doing anything related to large-scale ML deployments (as algorithm designers, engineers, or on the business side). I think this could bias your opinion formation in general. I can think of a few specific directions that this could happen but would first like to get an idea from you about who the other people you talked with were.

One bias is in terms of the excessive focus on the conceptually hardest parts of a problem as the most important ones. Some of the conceptually hardest problems -- like identifying a particular speaker, face, or object in a video or photo -- are commercially valuable, but their commercial value isn't necessarily proportional to their hardness, nor do they pave a path to general intelligence. R
